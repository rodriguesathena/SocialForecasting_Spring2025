---
title: "Social Forecasting Tutorial 5"
author: "Martyn Egan"
date: "14/04/2023"
output: html_document
---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(forecast)
library(zoo)
library(lubridate)
library(caret)

setwd(getwd())
```

# External Information and Binary Outcomes

Last week we looked at model-based methods in time series forecasting, including linear-type models and ARIMA. This week, we will look at how to add additional predictors to our models, as well as forecasting binary outcomes.

## Regression Models

Adding additional predictors to a time-series linear model is a relatively simple procedure. The `tslm()` function in the `forecast` package will accept additional variables in a similar manner to the `lm()` function in base `R`. We will use the `BikeSharingDaily.csv` dataset to demonstrate the procedure. The first code chunk is taken from the course reader, and is for preparing the data.

```{r external information preparation}
# Load and prepare data.
bike.df <- read.csv("data/BikeSharingDaily.csv")
bike.df$Date <- as.Date(bike.df$dteday, format = "%Y-%m-%d")
bike.df$Month <- month(bike.df$Date, label = TRUE)
bike.df$DOW <- wday(bike.df$Date, label = TRUE)
bike.df$WorkingDay <- factor(bike.df$workingday, levels = c(0, 1), labels = c("Not_Working", "Working"))
bike.df$Weather <- factor(bike.df$weathersit, levels = c(1, 2, 3), labels = c("Clear", "Mist", "Rain_Snow"))

# Create dummy variables.
Month.dummies <- model.matrix(~ 0 + Month, data = bike.df)
DOW.dummies <- model.matrix(~ 0 + DOW, data = bike.df)
WorkingDay_Weather.dummies <- model.matrix(~ 0 + WorkingDay:Weather, data = bike.df)

# Change the names of the dummy variables.
colnames(Month.dummies) <- gsub("Month", "", colnames(Month.dummies))
colnames(DOW.dummies) <- gsub("DOW", "", colnames(DOW.dummies))
colnames(WorkingDay_Weather.dummies) <- gsub("WorkingDay", "", colnames(WorkingDay_Weather.dummies))
colnames(WorkingDay_Weather.dummies) <- gsub("Weather", "", colnames(WorkingDay_Weather.dummies))
colnames(WorkingDay_Weather.dummies) <- gsub(":", "_", colnames(WorkingDay_Weather.dummies))

# Set up training and validation sets.
x <- as.data.frame(cbind(Month.dummies[, -12], DOW.dummies[, -7], WorkingDay_Weather.dummies[, -6]))
y <- bike.df$cnt
nTotal <- length(y)
nValid <- 90
nTrain <- nTotal - nValid
xTrain <- x[1:nTrain, ]
yTrain <- y[1:nTrain]
xValid <- x[(nTrain + 1):nTotal, ]
yValid <- y[(nTrain + 1):nTotal]
```

The above code wrangles the `.csv` file into an appropriate format for our regression model: numerical data are transformed into correctly formatted factors; dummy variables are created for month and day of week to model seasonality; additional vectors are created with external information, consisting of a cross-combination of working day and weather. Finally, the data are split into train and validate sets. Note that our target, `y`, is now a separate object to our predictor variables.

```{r data}
head(xTrain)
```

The next stage is to create a `ts` object from the target variable, `y`, and to run a regression model with our predictor variables, `xTrain`.

```{r regression model}
yTrain.ts <- ts(yTrain) #create ts object

(formula <- as.formula(paste("yTrain.ts", paste(c("trend", colnames(xTrain)), collapse = "+"), sep = "~"))) #create a formula object to pass to tslm

bike.tslm <- tslm(formula, data = xTrain, lambda = 1)
options(scipen = 999, digits = 6)
summary(bike.tslm)
```

Note that the model contains a coefficient for `trend`, which is the daily trend component calculated by the `tslm()` function. The additional coefficients are linear components for seasonality (month and day of week), and weather/workday. Note that there is a reference category for each to avoid collinearity, i.e. the intercept can be defined as a Saturday in December which is a working day and raining/snowing (is this a credible combination? What implications might this have for the model?)

```{r test and visualise}
bike.tslm.pred <-  forecast(bike.tslm, newdata = xValid)
accuracy(bike.tslm.pred, yValid)
checkresiduals(bike.tslm.pred)

y.ts<- ts(y)
times.ts <- time(y.ts)

plot(bike.tslm.pred, ylim = c(0, 9000), xlab = "Days", ylab = "Daily Bike Rentals")
lines(window(y.ts, start = times.ts[nValid + 1]))
```

How do we interpret the output? The Ljung-Box test is highly significant, which suggests the residuals are not white noise. Looking at the Acf, we can see high levels of autocorrelation within the first few lags. This often happens with long time series, but suggests that there is information which the linear model isn't capturing. Looking at the forecast as well, the errors are quite large. Can we do better?

## Dynamic Regression

Dynamic regression allows us to incorporate the benefits of ARIMA within a multivariate time series regression. Similarly to the AR method we saw last week, dynamic regression essentially models the residuals (the error term) as an ARIMA process. Let's compare the models.

```{r dynamic regression}
bike.dyn <- auto.arima(yTrain, xreg = as.matrix(xTrain)) #xreg requires a matrix

bike.dyn.pred <- forecast(bike.dyn, xreg = as.matrix(xValid)) #xreg functions here like the newdata arg

accuracy(bike.dyn.pred, yValid)
checkresiduals(bike.dyn.pred)

plot(bike.dyn.pred, ylim = c(0, 9000), xlab = "Days", ylab = "Daily Bike Rentals")
lines(window(y.ts, start = times.ts[nValid + 1]))
```

Dynamic Regression seems to do a worse job "out of the box" here. Remember though how our data are highly seasonal, which can affect ARIMA. Perhaps if we used a different process (rather than dummy variables) to model seasonality, dynamic regression might perform better?

## Dynamic Harmonic Regression

Similarly to the sin and cosine transformations for seasonality we looked at briefly last week, dynamic harmonic regression allows us to incorporate multivariate seasonal data within an ARIMA model, through what are known as Fourier terms. Fourier terms have a value, *K*, which cannot be more than half the seasonal period, and which essentially indicates how smooth or jagged the seasonality should be. Fourier terms allow for large seasonality to be included (e.g. 365 days, etc.)

```{r dynamic harmonic regression}
# First, we create an msts (a ts with multiple seasonality), here days and months
Train.msts <- msts(y[1:nTrain], seasonal.periods = c(7, 28))
Valid.msts <- msts(y[(nTrain + 1):nTotal], seasonal.periods = c(7, 28))

# Then we run the regression with fourier terms
bike.dyn.ha <- auto.arima(Train.msts, xreg = cbind(fourier(Train.msts, K = c(3, 11)),
                                               as.matrix(xTrain[,18:22])), seasonal = FALSE)

bike.dyn.ha.pred <- forecast(bike.dyn.ha, xreg = cbind(fourier(Valid.msts, 
                                                               K = c(3, 11), 
                                                               h = 90),
                                                       as.matrix(xValid[,18:22])))

accuracy(bike.dyn.ha.pred, yValid)
checkresiduals(bike.dyn.ha.pred)

new.msts <- msts(c(rep(NA, 641), Valid.msts), seasonal.periods = c(7,28))

plot(bike.dyn.ha.pred, ylim = c(0, 9000), xlab = "Months", ylab = "Daily Bike Rentals")
lines(window(new.msts))
```

Here, dynamic harmonic regression performs quite badly: notice that it is difficult to fit precise calendar months within a Fourier term; also, we are possibly losing too much information by dropping the other variables from the model (month and day of the week). Fourier models assume that seasonality does not evolve over time, which in this case is probably too strong an assumption. Remember that if we want to incorporate some of the benefits of autoregression in our model, we could also train an AR(1) model on the errors from our linear model, as in last week's class.

## Binary Outcomes

The final forecasting technique we will look at concerns binary outcomes. As with cross-sectional data, the technique used here is logistic regression, in which we model the relationship between the odds of the event of interest and the predictors. For forecasting purposes, we select a cutoff value above which the prediction is 1. 

As with other forecasting methods, lagged predictors (where available) can be useful in forecasting binary outcomes: when the binary outcome is based on a continuous measurement (stock price, blood sugar, rainfall, etc.) it can be more useful to include the lagged predictor of the actual measurement, rather than the binary value.

The below example uses the `MelbourneRainfall.csv` dataset to forecast rainy days (yes/no) using only rainfall amounts. We use the `glm()` function, with which you are already familiar, to model binary outcomes; it is not necessary to convert the data frame to a time series object for use with `glm()`. We do however perform several operations such as lagging and the use of seasonal smoothing. We will also use the `caret` package to create a confusion matrix of forecast outcomes.

```{r binary outcomes}
rain <- read.csv("data/MelbourneRainfall.csv")

rain$Date <- as.Date(rain$Date, format = "%d/%m/%Y")
rain$Rainy <- ifelse(rain$Rainfall > 0, 1, 0)

rain$Lag1 <- c(NA, rain$Rainfall[1:nrow(rain)-1])
rain$t <- seq(1, nrow(rain), 1)

rain$Seasonal_sine <- sin(2*pi*rain$t/365.25)
rain$Seasonal_cosine <- cos(2*pi*rain$t/365.25)

train <- rain[rain$Date <= as.Date("31/12/2009", format = "%d/%m/%Y"), ]
train <- train[-1,]
valid <- rain[rain$Date > as.Date("31/12/2009", format = "%d/%m/%Y"), ]

rainy.mod <- glm(Rainy ~ Lag1 + Seasonal_sine + Seasonal_cosine, 
                 data = train, 
                 family = "binomial")

summary(rainy.mod)

rainy.pred <- predict(rainy.mod, valid[, c(4, 6, 7)], type = "response")

confusionMatrix(as.factor(ifelse(rainy.mod$fitted > 0.5, 1, 0)), 
                as.factor(train$Rainy),
                positive = "1")
confusionMatrix(as.factor(ifelse(rainy.pred > 0.5, 1, 0)), 
                as.factor(valid$Rainy),
                positive = "1")
```

As the confusion matrix demonstrates, the model is quite accurate at predicting no-rain days (94.7% - the specificity score) and about 20% accurate at predicting rarer rainy days (sensitivity).

## A Final Word on External Information...

When using external information (i.e. additional predictors) to forecast time series data, we always need to think about the real life scenario in which the model will be used. 

Take the bike rental case above: it's clear that there is some *thing* which is leading to a sharp fall in demand that none of our models is capturing. What could this omitted variable be?

Perhaps more importantly, think about the external information we're using. What variable in our model could be problematic for *forecasting* demand? How might we better model this uncertainty in our forecast?

### Case Study

The `bicup2006.csv` dataset contains historic information on passengers arriving at a public bus terminal in five-minute periods for a three-week window. Your goal is to create a model with the best predictive metrics, using a two-week training period and a one week validation period.

```{r case study, eval = FALSE}
bicup <- read.csv("data/bicup2006.csv")
```